name: faq_query
type: serial
description: FAQ-based Question Answering query flow.
input:
  schema:
    input:
      type: object
      required:
      - query
      properties:
        query:
          type: string
          description: The user's query.
    output:
      type: object
      properties:
        content:
          type: string
          description: The assistant's reply.
  tasks:
  - name: calculate_embedding
    type: call
    input:
      loader: llmflow
      task: embedding_openai
      input:
        texts:
        - ${input.query}
  - name: query_documents
    type: vectorstore_query
    input:
      min_score: 0.7
      top_k: 3
      vector: ${calculate_embedding.embeddings[0]}
      vendor: memory
  - name: similar_documents
    type: decision
    input:
      expression: ${str(len(query_documents.similarities))}
      cases:
        "0":
          name: sorry
          type: terminate
          input:
            output:
              content: 对不起，我不知道。
      default:
        name: switch
        type: serial
        input:
          tasks:
          - name: build_prompt
            type: template
            input:
              args:
                query: ${input.query}
                documents: ${query_documents.similarities}
              template: |-
                Answer the question using the provided context.
                            
                Context:
                {{- range $.documents}}
                {{- $extra := jsonUnmarshal .extra}}
                Q: {{.text}}
                A: {{$extra.答}}
                {{- end}}

                Q: {{$.query}}
                A:
          - name: ask_llm
            type: call
            input:
              loader: llmflow
              task: llm_openai
              input:
                messages:
                - role: user
                  content: ${build_prompt.result}
